{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45fddc03-95c9-4111-9e20-63fc7c2cc341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (0.0.249)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.0.16)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.29.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "#install langchain\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a300bb3-865c-4d33-bfea-b12f634f6396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (2.29.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#install openAi\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63ccdc9-7582-46b9-b2f3-b28df1cae241",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting loguruNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
      "                                              0.0/60.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.0/60.0 kB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\sakshisingh57\\appdata\\local\\anaconda3\\lib\\site-packages (from loguru) (0.4.6)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru)\n",
      "  Downloading win32_setctime-1.1.0-py3-none-any.whl (3.6 kB)\n",
      "Installing collected packages: win32-setctime, loguru\n",
      "Successfully installed loguru-0.7.0 win32-setctime-1.1.0\n"
     ]
    }
   ],
   "source": [
    "#install logger\n",
    "pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71aabe95-0bb7-4864-9987-81180c7b47ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redis\n",
      "  Downloading redis-4.6.0-py3-none-any.whl (241 kB)\n",
      "                                              0.0/241.1 kB ? eta -:--:--\n",
      "     -------------------------------------- 241.1/241.1 kB 7.4 MB/s eta 0:00:00\n",
      "Installing collected packages: redis\n",
      "Successfully installed redis-4.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#install redis\n",
    "pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca6d2a9-bfd0-45dc-ad22-ade8c13459ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import redis\n",
    "from langchain.memory import RedisChatMessageHistory\n",
    "\n",
    "history = RedisChatMessageHistory(\"New\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7227bd5a-86ef-4be4-afb4-bd5acfc2503d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "\n",
    "from langchain.callbacks import FileCallbackHandler\n",
    "#logging into the file\n",
    "logfile = \"./mermaid/outputFlowDiaNew.log\"\n",
    "\n",
    "logger.add(logfile, colorize=True, enqueue=True)\n",
    "handler = FileCallbackHandler(logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9ab45be-df96-4837-b65b-a5b14adae95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "361e402b-11c8-4db0-a992-2b9afc011f07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "#count tokens\n",
    "def count_tokens(chain, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        count = chain.run(query)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a970b603-ffd5-422e-951f-28b1a0420581",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "modell = \"gpt-3.5-turbo\"\n",
    "\n",
    "# first initialize the large language model\n",
    "llm = ChatOpenAI(model= modell, temperature=0.7, max_tokens=1024, top_p=1, openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# now initialize the conversation chain\n",
    "conversation = ConversationChain(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b004531-fab4-4144-b857-13decf0be596",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "systemInput = \"Convert the following text to MermaidJS markup, do not explain and give the exact syntax : \";\n",
    "userInput = \"For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.\"\n",
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e250af8-dcbc-4028-8b6b-d1df2ca01812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "\n",
    "conversation_buf = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8503b761-54a3-4757-bf6c-0b9a414ddf8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-03 12:37:27.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1m{'input': 'Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.', 'history': 'Human: Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.\\nAI: ```mermaid\\ngraph LR\\nA((Start)) --> B(Have money)\\nB --> C(Go shopping)\\nC --> D(Think about what to buy)\\nD --> E{iPhone}\\nD --> F[Car]\\nD --> G[Laptop]\\n```\\n\\nHuman: Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.\\nAI: ```mermaid\\ngraph LR\\nA((Start)) --> B(Have money)\\nB --> C(Go shopping)\\nC --> D(Think about what to buy)\\nD --> E{iPhone}\\nD --> F[Car]\\nD --> G[Laptop]\\n```\\nHuman: Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.\\nAI: ```mermaid\\ngraph LR\\nA((Start)) --> B(Have money)\\nB --> C(Go shopping)\\nC --> D(Think about what to buy)\\nD --> E{iPhone}\\nD --> F[Car]\\nD --> G[Laptop]\\n```\\nHuman: Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.\\nAI: ```mermaid\\ngraph LR\\nA((Start)) --> B(Have money)\\nB --> C(Go shopping)\\nC --> D(Think about what to buy)\\nD --> E{iPhone}\\nD --> F[Car]\\nD --> G[Laptop]\\n```', 'response': '```mermaid\\ngraph LR\\nA((Start)) --> B(Have money)\\nB --> C(Go shopping)\\nC --> D(Think about what to buy)\\nD --> E{iPhone}\\nD --> F[Car]\\nD --> G[Laptop]\\n```'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 748 tokens\n"
     ]
    }
   ],
   "source": [
    "print(systemInput + userInput)\n",
    "result = conversation_buf(systemInput + userInput)\n",
    "tokens = count_tokens(conversation_buf, (systemInput + userInput))\n",
    "#adding Human messages and AI messages\n",
    "history.add_user_message(result['input'])\n",
    "history.add_ai_message(result['response'])\n",
    "logger.info(result)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35fbf964-7368-4a27-b59e-b56107f774a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```mermaid\n",
      "graph LR\n",
      "A((Start)) --> B(Have money)\n",
      "B --> C(Go shopping)\n",
      "C --> D(Think about what to buy)\n",
      "D --> E{iPhone}\n",
      "D --> F[Car]\n",
      "D --> G[Laptop]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(result['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b00be615-79b9-4607-8a95-2976ef3acf23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```mermaid\n",
      "graph LR\n",
      "A((Start)) --> B(Have money)\n",
      "B --> C(Go shopping)\n",
      "C --> D(Think about what to buy)\n",
      "D --> E{iPhone}\n",
      "D --> F[Car]\n",
      "D --> G[Laptop]\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-03 12:37:40.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mFlow Diagram generated Successfully, Model : gpt-3.5-turbo and Total Tokens : ```mermaid\n",
      "graph LR\n",
      "A((Start)) --> B(Have money)\n",
      "B --> C(Go shopping)\n",
      "C --> D(Think about what to buy)\n",
      "D --> E{iPhone}\n",
      "D --> F[Car]\n",
      "D --> G[Laptop]\n",
      "```\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "graph=result['response']\n",
    "\n",
    "print(graph)\n",
    "\n",
    "\n",
    "\n",
    "# Find the index of the first occurrence of \"graph LR\"\n",
    "start_index = graph.find(\"graph\")\n",
    "\n",
    "# Find the index of the last occurrence of \"]\" after \"D --> G[Laptop]\"\n",
    "end_index = graph.rfind(\"]\", graph.find(\"D --> G[Laptop]\"))\n",
    "\n",
    "# Extract the desired part of the string\n",
    "desired_part = graph[start_index:end_index + 1]\n",
    "\n",
    "graphbytes = desired_part.encode(\"ascii\")\n",
    "\n",
    "\n",
    "\n",
    "base64_bytes = base64.b64encode(graphbytes)\n",
    "base64_string = base64_bytes.decode(\"ascii\")\n",
    "\n",
    "img = Image.open(io.BytesIO(requests.get('https://mermaid.ink/img/' + base64_string).content))\n",
    "img.show()\n",
    "logger.info(\"Flow Diagram generated Successfully, Model : \" + modell + \" and Total Tokens : \" + tokens)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc28ddc0-33c1-4f9e-9d59-92f791add5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The MermaidJS markup for the given text would be as follows:\\n\\n```\\ngraph LR\\nA[Christmas shopping] --> B[Have money]\\nB --> C[Go shopping]\\nC --> D[Think what to buy]\\nD --> E[iPhone]\\nD --> F[Car]\\nD --> G[Laptop]\\n```\\n\\nThis markup represents a flowchart where \"Christmas shopping\" is the starting point, and it is connected to \"Have money\" through an arrow. \"Have money\" is connected to \"Go shopping,\" which is then connected to \"Think what to buy.\" From \"Think what to buy,\" there are three options to choose from: \"iPhone,\" \"Car,\" and \"Laptop,\" each connected through separate arrows.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The MermaidJS markup for the given text would be as follows:\\n\\n```\\ngraph LR\\nA[Christmas shopping] --> B[Have money]\\nB --> C[Go shopping]\\nC --> D[Think what to buy]\\nD --> E[iPhone]\\nD --> F[Car]\\nD --> G[Laptop]\\n```\\n\\nThis markup represents a flowchart where \"Christmas shopping\" is the starting point, and it is connected to \"Have money\" through an arrow. \"Have money\" is connected to \"Go shopping,\" which is then connected to \"Think what to buy.\" From \"Think what to buy,\" there are three options to choose from: \"iPhone,\" \"Car,\" and \"Laptop,\" each connected through separate arrows.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.', additional_kwargs={}, example=False),\n",
       " AIMessage(content='```mermaid\\ngraph LR\\nA[Christmas shopping] --> B[Have money]\\nB --> C[Go shopping]\\nC --> D[Think what to buy]\\nD --> E[iPhone]\\nD --> F[Car]\\nD --> G[Laptop]\\n```\\n', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.', additional_kwargs={}, example=False),\n",
       " AIMessage(content='To convert the given text to MermaidJS markup, you can use the following syntax:\\n\\n```\\ngraph LR\\nA((Start)) --> B(Money)\\nB --> C(Shopping)\\nC --> D(Think)\\nD --> E(iPhone)\\nD --> F(Car)\\nD --> G(Laptop)\\n```\\n\\nThis will create a flowchart representation of the given text, showing the sequential steps involved in the process of Christmas shopping.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.', additional_kwargs={}, example=False),\n",
       " AIMessage(content='I\\'m sorry, but as an AI text-based model, I cannot directly convert text to MermaidJS markup. However, I can provide you with a description of how you can convert the given text into MermaidJS markup.\\n\\nTo convert the given text to MermaidJS markup, you can use the following syntax:\\n\\n```mermaid\\ngraph LR\\nA[Start] --> B(Have money)\\nB --> C(Go shopping)\\nC --> D(Think what to buy)\\nD --> E{iPhone, car or laptop}\\n```\\n\\nIn the above markup, `graph LR` indicates that we are creating a directed graph from left to right. The letters inside the square brackets represent the nodes or steps in the process, and the arrows (`-->`) indicate the flow or sequence of steps.\\n\\nSo, to summarize the conversion:\\n\\n1. Start with the \"Start\" node.\\n2. Move to the \"Have money\" node.\\n3. From the \"Have money\" node, go to the \"Go shopping\" node.\\n4. From the \"Go shopping\" node, move to the \"Think what to buy\" node.\\n5. Finally, from the \"Think what to buy\" node, you have the options of \"iPhone,\" \"car,\" or \"laptop\" represented by the `{iPhone, car or laptop}`.\\n\\nPlease note that MermaidJS markup is typically used to create diagrams and flowcharts, so the converted markup represents the sequence of steps in the given text.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.', additional_kwargs={}, example=False),\n",
       " AIMessage(content='```mermaid\\ngraph LR\\nA((Start)) --> B(Have money)\\nB --> C(Go shopping)\\nC --> D(Think about what to buy)\\nD --> E{iPhone}\\nD --> F[Car]\\nD --> G[Laptop]\\n```\\n', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.', additional_kwargs={}, example=False),\n",
       " AIMessage(content='```mermaid\\ngraph LR\\nA((Start)) --> B(Have money)\\nB --> C(Go shopping)\\nC --> D(Think about what to buy)\\nD --> E{iPhone}\\nD --> F[Car]\\nD --> G[Laptop]\\n```', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Convert the following text to MermaidJS markup, do not explain and give the exact syntax : For christmas shopping, we need first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop.', additional_kwargs={}, example=False),\n",
       " AIMessage(content='```mermaid\\ngraph LR\\nA((Start)) --> B(Have money)\\nB --> C(Go shopping)\\nC --> D(Think about what to buy)\\nD --> E{iPhone}\\nD --> F[Car]\\nD --> G[Laptop]\\n```', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c3936-0a55-474e-8fe3-acd92db71f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
